# Time-Domain Bayesian Inference for Gravitational Wave Ringdown Analysis

<<<<<<< HEAD


This repository contains a Python-based framework for performing Bayesian inference on the ringdown portion of a gravitational wave signal. The analysis is conducted directly in the time domain using a custom likelihood built for the `bilby` inference library. The code is designed to analyze data for specific events, with `GW231123` used as the primary example.

The core of this project is a time-domain "Fast Bayesian Inference" (FBI) likelihood that uses pre-calculated auto-correlation functions (ACFs) to characterize the noise, allowing for efficient parameter estimation of black hole merger remnants.



## Project Workflow



The analysis is a two-step process, supported by a core likelihood module:

1. **Data Preparation (`save_psd_acf_GW231123.py`):**
   - Downloads and processes raw gravitational wave data from GWOSC (`.gwf` files).
   - Calculates the Power Spectral Density (PSD) and the Auto-Correlation Function (ACF) of the detector noise.
   - Saves the conditioned strain data and the ACFs to a `.npy` file.
2. **Bayesian Analysis (`td_FBI.py`):**
   - Loads the pre-processed data from the previous step.
   - Uses the custom time-domain likelihood defined in `td_likelihood.py`.
   - Runs the `dynesty` nested sampler via `bilby` to estimate the posterior distributions of the ringdown signal parameters (e.g., final mass, final spin, mode amplitudes).
   - Saves the results, including corner plots and posterior data.



## File Descriptions



- `td_likelihood.py`: A library module containing the core components of the analysis. It is not meant to be run directly.
  - `RDTDFBITransient`: The custom `bilby` likelihood class for time-domain ringdown analysis.
  - `TDWaveformGenerator`: A `bilby` waveform generator with a caching mechanism to speed up repeated calls.
  - `pycbc_ringdown_lmn`: The source model function that generates ringdown waveforms using `pycbc`.
- `save_psd_acf_GW231123.py`: A script to download, process, and prepare the data needed for the analysis. **This must be run first.**
- `td_FBI.py`: The main script that runs the Bayesian parameter estimation analysis using the data generated by the preparation script.



## Prerequisites



You will need Python 3.8+ and the following packages. We strongly recommend using a virtual environment.

- `bilby`
- `pycbc`
- `numpy`
- `scipy`
- `gwpy`
- `lalsuite`



## Installation and Setup



1. **Clone the Repository**

   Bash

   ```
   git clone https://github.com/your-username/your-repository-name.git
   cd your-repository-name
   ```

2. **Create a Virtual Environment and Install Dependencies**

   Bash

   ```
   python -m venv venv
   source venv/bin/activate
   pip install bilby pycbc numpy scipy gwpy lalsuite
   ```

3. Create Required Directories

   The scripts expect a specific directory structure. Create them in the root of the project:

   Bash

   ```
   mkdir Data
   mkdir TD_data
   ```

4. Download Gravitational Wave Data

   The data preparation script requires the raw frame files (.gwf) from the GWOSC archive. For the example event GW231123, you need to download the 4kHz data around the event time 1384782888.

   - Go to the [GWOSC Data Release for O4a](https://www.google.com/search?q=https://www.gw-openscience.org/data/O4a/).
   - Find the data files corresponding to the segment `1384779776-4096` for both the H1 and L1 detectors. The filenames will look like:
     - `H-H1_GWOSC_DiscO4a_4KHZ_R1-1384779776-4096.gwf`
     - `L-L1_GWOSC_DiscO4a_4KHZ_R1-1384779776-4096.gwf`
   - Place these two `.gwf` files inside the `Data/` directory you created.



## Usage



Follow these steps in order to run a complete analysis.



### Step 1: Prepare the Data



First, run the data preparation script. This will process the `.gwf` files and create a single `.npy` file containing the strain data, PSDs, and ACFs needed for the analysis.

Bash

```
python save_psd_acf_GW231123.py
```

After this script finishes, you should see a file named `PyCBC_psd_acfs_GW231123_20-1024Hz_t8s-v0.npy` inside the `TD_data/` directory.



### Step 2: Run the Bayesian Analysis



Now you can run the main analysis script. It is configured with command-line arguments for flexibility.

**To run a default analysis (220 mode, 10M time delay):**

Bash

```
python td_FBI.py
```

**To run a more complex analysis (e.g., 220 + 200 modes, 15M time delay):**

Bash

```
python td_FBI.py --modes '221,201' --time-delay-multiplier 15
```

**To specify a custom output directory:**

Bash

```
python td_FBI.py --outdir 'my_analysis_run'
```

The script will create a new directory for the results (e.g., `FBI_analysis_results/221+201_15M_0-4s/`) containing posterior samples, run metadata, and a corner plot of the key physical parameters.

------
=======
## Noise estimated by the pyRing packge
### With a sample rate at 2048 Hz
rin_2k.ini
### With a sample rate at 16384 Hz
rin_8k.ini

# Noises here are used for analyses in arXiv: 2311.13300
## The pyRing version is [2.1.0](https://git.ligo.org/lscsoft/pyring/-/tree/v2.1.0?ref_type=tags). The PyCBC version is [2.0.5](https://github.com/gwastro/pycbc/tree/v2.0.5)
>>>>>>> 5def845f9c2691e9e94ff6a0927f401e06444513
